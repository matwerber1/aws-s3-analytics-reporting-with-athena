AWSTemplateFormatVersion: '2010-09-09'
Description: >
  This template deploys an AWS Glue catalog database and table for S3 analytics 
  reports, a Glue crawler to catalog your reports as partitions in the table,
  and an S3 event to trigger the crawler when new reports are delivered. 

Metadata: 
  AWS::CloudFormation::Interface: 
    ParameterGroups: 
      - 
        Label: 
          default: "Glue Catalog Configuration"
        Parameters: 
          - DatabaseName
          - TableName
          - CrawlerName
      - 
        Label: 
          default: "S3 Analytics Configuration"
        Parameters: 
          - ReportDeliveryBucket
          - ReportDeliveryKeyPrefix
    ParameterLabels: 
      DatabaseName: 
        default: "Analytics database name?"
      TableName: 
        default: "Analytics table name?"
      ReportDeliveryBucket: 
        default: "S3 bucket to which your reports are delivered?"
      ReportDeliveryKeyPrefix: 
        default: "S3 key prefix for your analytics reports?"

Parameters: 

  DatabaseName: 
    Type: String
    Default: s3_analytics_db
    Description: >
      Name of the AWS Glue catalog database to contain your S3 analytics table

  TableName: 
    Type: String
    Default: s3_analytics
    Description: >
      Name of the AWS Glue catalog table to contain your S3 analytics data. This
      *must* be identical to the lowest-level folder in your analytics report
      destination prefix before the "bucket=" portion. For example, if you specified
      a prefix of "reports/s3_analytics/bucket=SOURCE_BUCKET", then this parameter
      should be "s3_analytics". If you only specified "s3_analytics/bucket-SOURCE_BUCKET",
      this parameter would still just be "s3_analytics".

  CrawlerName: 
    Type: String
    Default: s3-analytics-crawler
    Description: >
      Name of the AWS Glue crawler that will add our S3 analytics reports to
      our report table in the Glue catalog. 

  ReportDeliveryBucket: 
    Type: String
    Default: YOUR_REPORT_BUCKET
    Description: >
      S3 bucket to which all of your S3 analytics reports are being delivered

  ReportDeliveryKeyPrefix:
    Type: String
    Description: > 
      The delivery prefix in your S3 analytics configuration, excluding the 
      "/bucket=source_bucket" portion. In other words, if your delivery prefix is
      "s3_analytics/bucket=my_bucket", then this parameter value should be "s3_analytics".
      If you use nested multiple folders in your prefix, those should be included too.
      For example, if your prefix was "reports/s3_analytics/bucket=my_bucket", then
      this parameter value should be "reports/s3_analytics". Do not include a trailing
      slash.

    Default: s3_analytics

Resources: 
  #-----------------------------------------------------------------------------
  # AWS Glue Resources
  #-----------------------------------------------------------------------------
  S3AnalyticsDatabase:
    Type: AWS::Glue::Database
    Properties: 
      CatalogId: !Ref AWS::AccountId
      DatabaseInput:
        Name: !Ref DatabaseName
        Description: Contains S3 Analytics reports for buckets on which analytics has been enabled. 
        LocationUri: !Sub "s3://${ReportDeliveryBucket}/${ReportDeliveryKeyPrefix}/"
            
  S3AnalyticsTable:
    Type: AWS::Glue::Table
    Properties: 
      CatalogId: !Ref AWS::AccountId
      DatabaseName: !Ref S3AnalyticsDatabase
      TableInput: 
        Name: !Ref TableName
        Description: Contains S3 Analytics reports for buckets on which analytics has been enabled. 
        TableType: EXTERNAL_TABLE
        Parameters:
          CrawlerSchemaDeserializerVersion: "1.0"
          CrawlerSchemaSerializerVersion: "1.0"
          areColumnsQuoted: "false"
          EXTERNAL: "TRUE"
          classification: "csv"
          columnsOrdered: "true"
          compressionType: "none"
          delimiter: ","
          skip.header.line.count: "1"
          typeOfData: "file"
        PartitionKeys: 
          - 
            Comment: S3 bucket from which a given report was derived.
            Name: bucket
            Type: string
        StorageDescriptor: 
          Location: !Sub "s3://${ReportDeliveryBucket}/${ReportDeliveryKeyPrefix}/"
          # Although Glue crawlers make a best effort to detect proper schema, 
          # anecdotal testing shows that the crawlers may pick up the wrong schema 
          # for some S3 analytics reports, depending on their content. Therefore, 
          # we must explicitly define our schema below:  
          Columns: 
            -
              Name: date
              Type: date
            -
              Name: config_id
              Type: string
            -
              Name: filter
              Type: string
            -
              Name: storage_class
              Type: string
            -
              Name: object_age
              Type: string
            -
              Name: object_count
              Type: bigint
            -
              Name: uploaded_mb
              Type: decimal(12,4)
            -
              Name: storage_mb
              Type: decimal(12,4)
            -
              Name: retrieved_mb
              Type: decimal(12,4)
            -
              Name: get_request_count
              Type: decimal(12,4)
            -
              Name: cumulative_access_ratio
              Type: decimal(12,4)
            -
              Name: age_for_sia_transition
              Type: string
            -
              Name: recommended_age_for_sia_transition
              Type: string
          Compressed: False
          InputFormat: "org.apache.hadoop.mapred.TextInputFormat"
          OutputFormat: "org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat"
          NumberOfBuckets: -1
          BucketColumns: []
          SortColumns: []
          Parameters: {}
          SerdeInfo: 
            SerializationLibrary: "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe"
            Parameters:
              "field.delim": ","
              "serialization.format": ","

  Crawler:
    Type: 'AWS::Glue::Crawler'
    DependsOn:
      - S3AnalyticsDatabase
      - CrawlerRole
    Properties:
      Name: !Ref CrawlerName
      Description: A crawler that keeps your S3 analytics table in Athena up-to-date.
      Role: !GetAtt CrawlerRole.Arn
      DatabaseName: !Ref S3AnalyticsDatabase
      # The configuration below is important, as it prevents the crawler from
      # modifying the schema we defined for our table, above. We do this because
      # testing shows that the Glue crawlers may detect the wrong schema for certain
      # reports, depending on their content. If there's a mismatch in schemas
      # between partitions, or if partition schemas don't match table schema, we
      # will receive an error when we later try to use Athena to query our table. 
      Configuration:  
        !Sub | 
          {
            "Version": 1.0, 
            "CrawlerOutput": {
              "Partitions": {
                "AddOrUpdateBehavior": "InheritFromTable" 
              }
            }
          }
          Version: 1.0
          CrawlerOutput:
            Partitions:
              AddOrUpdateBehavior: "InheritFromTable"
      Targets:
        S3Targets:
          - Path: !Sub "s3://${ReportDeliveryBucket}/${ReportDeliveryKeyPrefix}/"
      SchemaChangePolicy:
        # For same reasons described above, we do not want the crawler to change
        # our defined table schema, so we set the UpdateBehavior to LOG
        UpdateBehavior: LOG
        DeleteBehavior: DELETE_FROM_DATABASE

  CrawlerRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - glue.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole'
      Policies:
        - PolicyName: CrawlerComponentRole
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: 'arn:aws:logs:*:*:*'
              - Effect: Allow
                Action:
                  - 'glue:UpdateDatabase'
                  - 'glue:UpdatePartition'
                  - 'glue:CreateTable'
                  - 'glue:UpdateTable'
                  - 'glue:ImportCatalogToGlue'
                Resource: '*'
              - Effect: Allow
                Action:
                  - 's3:GetObject'
                  - 's3:PutObject'
                Resource: 
                  !Sub "arn:aws:s3:::${ReportDeliveryBucket}/${ReportDeliveryKeyPrefix}/*"

  #-----------------------------------------------------------------------------
  # LAMBDA TO TRIGGER CRAWLER
  #-----------------------------------------------------------------------------

  # This function triggers our Glue crawler and is used at two different times. 
  # First, it backs the custom CloudFormation resource StartAnalyticsCrawlerResource, 
  # which starts the crawler when our stack first deploys so we populate our table
  # with any existing reports right away. Second, it is invoked by an S3 Event 
  # any time a new S3 analytics report is delivered to our reporting bucket.
  RunCrawlerFunction:
    Type: 'AWS::Lambda::Function'
    DependsOn: Crawler
    Properties:
      Environment: 
        Variables: 
          CRAWLER_NAME: !Ref CrawlerName
      Code:
        ZipFile: >
          const AWS = require('aws-sdk');
          const response = require('cfn-response');
          exports.handler = function(event, context) {
            if (event.RequestType === 'Delete') {
              response.send(event, context, response.SUCCESS);
            } else {
              const glue = new AWS.Glue();
              glue.startCrawler({ Name: process.env['CRAWLER_NAME'] }, function(err, data) {
                if (err) {
                  const responseData = { msg: this.httpResponse.body.toString() };
                  response.send(event, context, response.FAILED, responseData);
                }
                else {
                  response.send(event, context, response.SUCCESS);
                }
              });
            }
          };
      Handler: 'index.handler'
      Timeout: 30
      Runtime: nodejs8.10
      ReservedConcurrentExecutions: 1
      Role: !GetAtt RunCrawlerFunctionRole.Arn

  RunCrawlerFunctionRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      Policies:
        - PolicyName: CrawlerFunctionRole
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: 'arn:aws:logs:*:*:*'
              - Effect: Allow
                Action:
                  - 'glue:StartCrawler'
                Resource: 
                  !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:crawler/${CrawlerName}"

  #-----------------------------------------------------------------------------
  # S3 EVENT TO TRIGGER LAMBDA THAT TRIGGERS CRAWLER
  #-----------------------------------------------------------------------------
  
  # Grant S3 Events permission to invoke our Lambda
  S3EventLambdaPermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !GetAtt RunCrawlerFunction.Arn
      Principal: 's3.amazonaws.com'
      SourceAccount: !Ref AWS::AccountId
      SourceArn: !Sub 'arn:aws:s3:::${ReportDeliveryBucket}'

  # You can only use native CloudFormation to create S3 Events if you are also
  # creating the source bucket in the same template. Since we are assuming that
  # the bucket to which our analytics reports are being delivered *already*
  # exists, we must instead make a PutBucketNotification() API call to create
  # the S3 Event. We do this with a custom CloudFormation resource & Lambda: 
  S3EventNotificationConfiguration:
    Type: 'Custom::AWSPutS3Notification'
    Properties:
      ServiceToken: !GetAtt S3EventNotificationProvider.Arn
      TargetLambdaArn: !GetAtt RunCrawlerFunction.Arn
      BucketName: !Ref ReportDeliveryBucket
      ReportKey: !Sub "${ReportDeliveryKeyPrefix}/"
  
  S3EventNotificationProvider:
    Type: 'AWS::Lambda::Function'
    DependsOn:
    - RunCrawlerFunction
    - S3EventNotificationProviderRole
    - S3EventLambdaPermission
    Properties:
      Code:
        ZipFile: >
          const AWS = require('aws-sdk');
          const response = require('cfn-response');
          exports.handler = function(event, context, callback) {
            console.log('Received event:\n' + JSON.stringify(event,null,2))
            const s3 = new AWS.S3();
            const putConfigRequest = function(notificationConfiguration) {
              return new Promise(function(resolve, reject) {
                s3.putBucketNotificationConfiguration({
                  Bucket: event.ResourceProperties.BucketName,
                  NotificationConfiguration: notificationConfiguration
                }, function(err, data) {
                  if (err) reject({ msg: this.httpResponse.body.toString(), error: err, data: data });
                  else resolve(data);
                });
              });
            };
            const newNotificationConfig = {};
            if (event.RequestType !== 'Delete') {
              newNotificationConfig.LambdaFunctionConfigurations = [{
                Events: [ 's3:ObjectCreated:*' ],
                LambdaFunctionArn: event.ResourceProperties.TargetLambdaArn || 'missing arn',
                Filter: { Key: { FilterRules: [ { Name: 'prefix', Value: event.ResourceProperties.ReportKey } ] } }
              }];
            }
            putConfigRequest(newNotificationConfig).then(function(result) {
              response.send(event, context, response.SUCCESS, result);
              callback(null, result);
            }).catch(function(error) {
              response.send(event, context, response.FAILED, error);
              console.log(error);
              callback(error);
            });
          };
      Handler: 'index.handler'
      Timeout: 30
      Runtime: nodejs8.10
      ReservedConcurrentExecutions: 1
      Role: !GetAtt S3EventNotificationProviderRole.Arn

  S3EventNotificationProviderRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      Policies:
        - PolicyName: PutS3EventNotification
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: 'arn:aws:logs:*:*:*'
              - Effect: Allow
                Action:
                  - 's3:PutBucketNotification'
                Resource: !Sub 'arn:aws:s3:::${ReportDeliveryBucket}'

  #-----------------------------------------------------------------------------
  # CUSTOM RESOURCE TO TRIGGER CRAWLER WHEN CLOUDFORMATION STACK FIRST LAUNCHES
  #-----------------------------------------------------------------------------
  # This custom resource simply triggers our crawler after its first created
  # so we can populate our table without needing to wait for a new analytics
  # report to get delivered and trigger an S3 Event -> Lambda. 
  StartAnalyticsCrawlerResource:
    Type: 'Custom::StartAnalyticsCrawler'
    Properties:
      ServiceToken: !GetAtt RunCrawlerFunction.Arn
